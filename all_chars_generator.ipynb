{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from consts import DATAROOT\n", "import pandas as pd\n", "import numpy as np\n", "from pathlib import Path\n", "import datetime"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%<br><br>\n", "Reading data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["daily_stock = pd.read_csv(Path(DATAROOT, \"stock_daily.csv\"))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["monthly_stock_wide = pd.read_csv(Path(DATAROOT, 'signed_predictors_dl_wide.csv'))\n", "monthly_stock_wide.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["daily_stock.columns = (col.lower() for col in daily_stock.columns)\n", "daily_stock['date'] = pd.to_datetime(daily_stock.date, format=\"%Y%m%d\")\n", "daily_stock.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["reference = pd.read_csv(Path(DATAROOT, \"CRSP_daily_stock_reference\"))\n", "reference['Variable Name'] = reference['Variable Name'].str.slice(0, -1)\n", "reference = reference[reference['Variable Name'].isin(daily_stock.columns)]\n", "reference['description_url'] = \"https://wrds-www.wharton.upenn.edu/data-dictionary/form_metadata/crsp_a_stock_dsf_identifyinginformation/\" + reference['Variable Name']\n", "reference.head(2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sp500_op_ret = pd.read_csv(Path(DATAROOT, \"sp500_op_ret.csv\"))\n", "sp500_op_ret['date'] = pd.to_datetime(sp500_op_ret['date'])\n", "sp500_op_ret['exdate'] = pd.to_datetime(sp500_op_ret['exdate'])\n", "sp500_op_ret.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mapping_table = pd.read_csv(Path(DATAROOT, \"mapping_table.csv\"))\n", "mapping_table.head(2)\n", "mapping_table['sdate'] = pd.to_datetime(mapping_table.sdate)\n", "mapping_table['edate'] = pd.to_datetime(mapping_table.edate)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "# Add permno to monthly data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["(mapping_table.groupby('secid').count()[mapping_table.groupby('secid').permno.count() != 1])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["(mapping_table.groupby('permno').count()[mapping_table.groupby('permno').secid.count() != 1])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mapping_table[mapping_table.permno == 10113]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mapping_table[mapping_table.secid == 5007]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def dates_overlaps(group):\n", "    if group.shape[0] == 1:\n", "        return False\n", "    else:\n", "        group.sort_values('sdate', inplace=True)\n", "        return ((group.edate - group.edate.shift(1)) < datetime.timedelta(0)).any()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mapping_table.groupby('secid').apply(dates_overlaps)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mapping_table.groupby('secid').apply(dates_overlaps)[mapping_table.groupby('secid').apply(dates_overlaps)]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mapping_table[mapping_table.secid == 5505]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "## Summary on mapping table: if we eliminate the secids 5505 and 9534, each (secid, sdate, edate) triplet gives uniquely a permno, so we shall use this to link the data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sp500_op_ret = sp500_op_ret[~sp500_op_ret.secid.isin([5505, 9534])]\n", "sp500_op_ret = sp500_op_ret[sp500_op_ret.date <= mapping_table.edate.max()]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def add_permno(group):\n", "    secid = group.secid.iloc[0]\n", "    mapping_group = MAPPING_GROUPED.get_group(secid)\n", "    def find_permno(row):\n", "        try:\n", "            return mapping_group[(mapping_group.sdate <= row.date) & (mapping_group.edate >= row.date)].permno.iloc[0]\n", "        except:\n", "            print('occurs') \n", "            # sometimes it occurs that the date falls between one edate and one sdate in the mapping table. \n", "            # This event is rare (happens twice in the initial sample), so will just return nan and drop na later.\n", "            return np.nan\n", "    if mapping_group.shape[0] == 1:\n", "        group['permno'] = mapping_group.permno.iloc[0]\n", "    else:\n", "        group['permno'] = group.apply(find_permno, axis=1)\n", "    return group"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MAPPING_GROUPED = mapping_table.groupby('secid')\n", "grouped = sp500_op_ret.groupby('secid')\n", "sp500_op_ret_w_permno = grouped.apply(add_permno).dropna(subset=['permno'])\n", "sp500_op_ret_w_permno"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sp500_op_ret_w_permno[sp500_op_ret_w_permno.option_ret.isna()]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "# Grouping daily data with month"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "First, we check whether all monthly data are recorded on the last trading date of the natural month."]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dates = pd.Series(daily_stock.date.dt.strftime('%Y-%m-%d').unique())\n", "end_of_trading_month = dates.groupby(dates.str.slice(0, 7)).max().values"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "There is one wierd date."]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sp500_op_ret_w_permno[~sp500_op_ret_w_permno.date.dt.strftime('%Y-%m-%d').isin(end_of_trading_month)].date.unique()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["daily_stock[daily_stock.date.dt.strftime('%Y-%m-%d') == '2017-09-30']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "However, we checked that 2017-09-30 is Saturday, and since there is only one record in this regard, we simply drop this record."]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["daily_stock = daily_stock[~(daily_stock.date.dt.strftime('%Y-%m-%d') == '2017-09-30')]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "Now everything's cool."]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dates = pd.Series(daily_stock.date.dt.strftime('%Y-%m-%d').unique())\n", "end_of_trading_month = dates.groupby(dates.str.slice(0, 7)).max().values\n", "sp500_op_ret_w_permno.date.dt.strftime('%Y-%m-%d').isin(end_of_trading_month).all()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["end_of_mon_dict = {date[0:7]: date for date in end_of_trading_month}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def last_date(group):\n", "    return pd.Series([group.date.max()] * group.shape[0], index=group.index)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["daily_stock['month'] = daily_stock.groupby(daily_stock.date.dt.strftime('%Y-%m')).apply(last_date).droplevel(0)\n", "daily_stock.sort_values('date', inplace=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["daily_stock['ind'] = daily_stock[~(daily_stock.siccd=='Z')].siccd.astype(str).str.slice(0,2).astype(int)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ind_info = daily_stock[['permno','month','ind']]\n", "eom_ind = ind_info.groupby(['permno', 'month']).apply(lambda group: group.ind.iloc[-1]).dropna().astype(int).astype(str)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ind_dummies = pd.get_dummies(eom_ind)\n", "ind_dummies.columns = [f'ind_{col}' for col in ind_dummies.columns]\n", "ind_dummies = ind_dummies.reset_index(drop=False)\n", "ind_dummies.columns = [(col if col!='month' else 'date') for col in ind_dummies.columns]\n", "ind_dummies"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "Now, when calculating the any monthly data, such as realized volatility, from daily data, we can simply do daily_stock.groupby(['permno', 'month']).apply(aggregation_func)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "# Aggregating calculations"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "#### List of attributes to be calculated from the daily data<br><br>\n", "    1.Realized volatility of stock price<br><br>\n", "    2.Volume of stocks traded<br><br>\n", "    3.Dollar volume of stocks traded"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["reference"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["attributes = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["daily_stock['dollar_volu'] = daily_stock['vol'] * daily_stock['prc']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["grouped = daily_stock.groupby(['permno', 'month'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rvol = (grouped['prc'].std() * np.sqrt(12)).rename('rvol')\n", "attributes += [rvol]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["share_volume = grouped['vol'].sum().rename('share_volume')\n", "attributes += [share_volume]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dollar_volume = grouped['dollar_volu'].sum().rename('dollar_volume')\n", "attributes += [dollar_volume]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["attributes_from_daily_stock = pd.DataFrame(attributes).T.reset_index()\n", "attributes_from_daily_stock"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sp500_op_ret_w_permno = pd.merge(sp500_op_ret_w_permno, attributes_from_daily_stock, left_on=['permno', 'date'], right_on=['permno', 'month'], how='inner')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "# Revisit Daily option data<br><br>\n", "From most of the characteristics in Bucket level, we need some volatility data on the options, so we dived back into the daily option data to hopefully make it possible to calculate more things.<br><br>\n", "<br><br>\n", "But failed..."]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%<br><br>\n", "daily_option = pd.read_csv(Path(DATAROOT, 'daily_option.csv'))<br><br>\n", "# reading this takes \\\\ sadly forever... "]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "# Calculating Characteristics"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "## Preliminary Work<br><br>\n", "We first add some preliminary columns to the dataframe<br><br>\n", "<br><br>\n", "Most of the works here are contributed by Natasha"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sp500_op_ret_w_permno[\"yrs_to_exp\"] = sp500_op_ret_w_permno[\"days_to_exp\"] / 250\n", "sp500_op_ret_w_permno[\"moneyness\"] = sp500_op_ret_w_permno['strike_price'] / sp500_op_ret_w_permno['adj_spot']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "# %%<br><br>\n", "months = sp500_op_ret_w_permno['date'].sort_values(ascending=True).unique()<br><br>\n", "months<br><br>\n", "int_months = [int(month) for month in months]# np.searchsorted works wierdly on dt objects <br><br>\n", "int_months"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "# %%<br><br>\n", "# shift option return<br><br>\n", "global I <br><br>\n", "I = 0<br><br>\n", "global L <br><br>\n", "L = len(sp500_op_ret_w_permno.optionid.unique())<br><br>\n", "# grouped = sp500_op_ret_w_permno.sort_values('date')[['optionid', 'date', 'option_ret']].groupby('optionid')<br><br>\n", "grouped = sp500_op_ret_w_permno.sort_values('date').groupby('optionid')<br><br>\n", "def get_all_months(group):<br><br>\n", "    s_month, e_month = np.datetime64(group.date.iloc[0]), np.datetime64(group.date.iloc[-1])<br><br>\n", "    return months[(months >= s_month) & (months <= e_month)]<br><br>\n", "    # return months[np.searchsorted(months, s_month): np.searchsorted(months, e_month)+1]<br><br>\n", "def get_prev_option_ret(group):<br><br>\n", "    signal_df = pd.DataFrame(get_all_months(group), columns=['date'])<br><br>\n", "    filled_group = pd.merge(group, signal_df, on='date', how='outer')<br><br>\n", "    filled_group['prev_option_ret'] = filled_group.option_ret.shift(1)<br><br>\n", "    global I<br><br>\n", "    I+=1<br><br>\n", "    print(I/L, end=\"\\r\")<br><br>\n", "    return filled_group.dropna(subset=['optionid'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "# %%<br><br>\n", "group = sp500_op_ret_w_permno.sort_values('date').groupby('optionid').get_group(10009003)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "# %%<br><br>\n", "sp500_op_ret_w_permno = grouped.apply(get_prev_option_ret).reset_index(drop=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "## Stock level"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "Start to calculate the option characteristics"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sp500_op_ret_w_permno.columns"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stock_level_grouped = sp500_op_ret_w_permno.groupby(['secid', 'date'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%<br><br>\n", "fucntions calculating characteristics in part 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "toi"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def toi(opt_data):\n", "    sp500_op_ret = opt_data\n", "    toi = sp500_op_ret.groupby([\"secid\", \"date\"])[\"open_interest\"].sum()\n", "    return toi\n", "# toitest=toi(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "pcrratio"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pcratio(opt_data):\n", "    sp500_op_ret = opt_data\n", "    put_vol_permnth_underlying = sp500_op_ret.drop(sp500_op_ret[sp500_op_ret.cp_flag == 'C'].index)\n", "    put_vol_permnth_underlying = put_vol_permnth_underlying.groupby(['secid', 'date'])[\"open_interest\"].sum()\n", "    put_vol_permnth_underlying.rename(\"oi_put\", inplace=True)\n", "    total_vol_permnth_underlying = sp500_op_ret.groupby(['secid', 'date'])[\"open_interest\"].sum()\n", "    total_vol_permnth_underlying.rename(\"oi_total\", inplace=True)\n", "    join = pd.concat([total_vol_permnth_underlying, put_vol_permnth_underlying], axis=1)\n", "    join = join.fillna(0)\n", "    ratio = join[\"oi_put\"] / join[\"oi_total\"]\n", "    return ratio\n", "# pcratiotest=pcratio(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def vol(opt_data):\n", "    sp500_op_ret = opt_data\n", "    vol = sp500_op_ret.groupby(['secid', 'date'])[\"volume\"].sum()\n", "    return vol\n", "# voltest=trading_vol(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "nopt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def nopt(opt_data):\n", "    sp500_op_ret = opt_data\n", "    nopt = sp500_op_ret.groupby(['secid', 'date'])[\"volume\"].mean()\n", "    return nopt\n", "# nopttest=n_opt(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "dvol group by option id"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def dvol(opt_data):\n", "    sp500_op_ret = opt_data\n", "    dvol = sp500_op_ret[\"volume\"] * sp500_op_ret[\"mid_price\"]\n", "    sp500_op_ret[\"dvol_temp\"] = dvol\n", "    dvol = sp500_op_ret.groupby(['secid', 'date'])[\"dvol_temp\"].sum()\n", "    return dvol\n", "# dvoltest=d_vol(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "ailliq"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def ailliq(opt_data):\n", "    sp500_op_ret = opt_data\n", "    ailliq_a = abs(sp500_op_ret['prev_option_ret']) / sp500_op_ret['dvol_temp']\n", "    sp500_op_ret[\"ailliq_a\"] = ailliq_a                                      \n", "    ailliq_a = sp500_op_ret.groupby(['secid', 'date'])[\"ailliq_a\"].sum()                                          \n", "    ailliq_b = sp500_op_ret.groupby(['secid', 'date'])[\"volume\"].sum()\n", "    ailliq = ailliq_a / ailliq_b\n", "    return ailliq\n", "# ailliqtest=a_illiq(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "pilliq"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pilliq(opt_data):\n", "    sp500_op_ret = opt_data\n", "    pilliq_a = abs(sp500_op_ret['prev_option_ret']) / sp500_op_ret['dvol_temp'] / sp500_op_ret['mid_price']\n", "    sp500_op_ret[\"pilliq_a\"] = pilliq_a                                      \n", "    pilliq_a = sp500_op_ret.groupby(['secid', 'date'])[\"pilliq_a\"].sum()                                          \n", "    pilliq_b = sp500_op_ret.groupby(['secid', 'date'])[\"volume\"].sum()\n", "    pilliq = pilliq_a / pilliq_b\n", "    return pilliq\n", "# pilliqtest=p_illiq(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "##"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pcpv(opt_data):\n", "    def get_PC_parity_vio(group):\n", "        group.sort_values(['exdate', 'cp_flag'], ascending=False, inplace=True)\n", "        s_grouped = group.groupby(['strike_price', 'exdate'])\n", "        candi_key = []\n", "        for key, s_group in s_grouped:  # record keys of such s_group that has length 2\n", "            if s_group.shape[0] == 2:\n", "                candi_key += [key]\n", "        if not candi_key:\n", "            return np.nan\n", "        elif len(candi_key) == 1:\n", "            pair = s_grouped.get_group(candi_key[0])\n", "        else:\n", "            current_spot = group.spotprice.iloc[0]\n", "            moneyness = [abs(key[0] - current_spot) for keys in candi_key]\n", "            pair_idx = candi_key[moneyness.index(min(moneyness))]\n", "            pair = s_grouped.get_group(pair_idx)\n", "        cal = pair.strike_price.iloc[0] * np.exp(-pair.ir_rate.iloc[0] * pair.days_to_exp.iloc[0] / 250) + pair.mid_price.iloc[1] - pair.mid_price.iloc[0]\n", "        L = 100 * np.log(pair.spotprice.iloc[0] / cal)\n", "        return L\n", "    pcpv = opt_data.groupby(['secid', 'date']).apply(get_PC_parity_vio)\n", "    return pcpv"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "pcpv=sp500_op_ret.groupby(['secid', 'date']).apply(get_PC_parity_vio)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def shrtfee(opt_data):\n", "    def shrt_fee(group):\n", "        group.sort_values(['exdate', 'cp_flag'], ascending=False, inplace=True)\n", "        s_grouped = group.groupby(['strike_price', 'exdate'])\n", "        candi_key = []\n", "        for key, s_group in s_grouped:  # record keys of such s_group that has length 2\n", "            if s_group.shape[0] == 2:\n", "                candi_key += [key]\n", "        if not candi_key:\n", "            return np.nan\n", "        elif len(candi_key) == 1:\n", "            pair = s_grouped.get_group(candi_key[0])\n", "        else:\n", "            current_spot = group.spotprice.iloc[0]\n", "            moneyness = [abs(key[0] - current_spot) for keys in candi_key]\n", "            pair_idx = candi_key[moneyness.index(min(moneyness))]\n", "            pair = s_grouped.get_group(pair_idx)\n", "        cal = pair.adj_spot.iloc[0] - pair.strike_price.iloc[0] * np.exp(-pair.ir_rate.iloc[0] * pair.days_to_exp.iloc[0] / 250) + pair.mid_price.iloc[0] - pair.mid_price.iloc[1]\n", "        L = (1 - cal / pair.adj_spot.iloc[0])**(1 / pair.strike_price.iloc[0])\n", "        M = (1 - L) / (1 + pair.ir_rate.iloc[0])\n", "        return M\n", "    shrt_fee = opt_data.groupby(['secid', 'date']).apply(shrt_fee)\n", "    return shrt_fee"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "iv_skew"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def skewiv(opt_data):\n", "    sp500_op_ret = opt_data\n", "    put_vals = sp500_op_ret.drop(sp500_op_ret[sp500_op_ret.cp_flag == 'C'].index)\n", "    call_vals = sp500_op_ret.drop(sp500_op_ret[sp500_op_ret.cp_flag == 'P'].index)\n", "    temp_callvals = call_vals.groupby(['secid', 'date'])[[\"impl_volatility\", \"moneyness\"]].mean()\n", "    temp_putvals = put_vals.groupby(['secid', 'date'])[[\"impl_volatility\", \"moneyness\"]].mean()\n", "    otmput = temp_putvals[((temp_putvals[\"moneyness\"] < 0.9))]\n", "    atmcall = temp_callvals[\n", "        (temp_callvals[\"moneyness\"] >= 0.9) & (temp_callvals[\"moneyness\"] <= 1.1)]\n", "    atmcall = atmcall[\"impl_volatility\"]\n", "    otmput = otmput[\"impl_volatility\"]\n", "    atmcall.rename(\"implvolatmcall\", inplace=True)\n", "    otmput.rename(\"implvolotmput\", inplace=True)\n", "    skewiv_temp = pd.concat([otmput, atmcall], axis=1)\n", "    skewiv = skewiv_temp[\"implvolotmput\"] - skewiv_temp[\"implvolatmcall\"]\n", "    return skewiv\n", "# skewivtest=iv_skew(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "atm_civpiv"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def atm_civpiv(opt_data):\n", "    sp500_op_ret = opt_data\n", "    atm_options = sp500_op_ret[(sp500_op_ret[\"moneyness\"] >= 0.9) & (sp500_op_ret[\"moneyness\"] <= 1.1)]\n", "    atm_puts = atm_options.drop(atm_options[atm_options.cp_flag == 'C'].index)\n", "    atm_calls = atm_options.drop(atm_options[atm_options.cp_flag == 'P'].index)\n", "    atm_puts = atm_puts.groupby(['secid', 'date'])[[\"impl_volatility\"]].mean()\n", "    atm_puts = atm_puts.rename(columns={\"impl_volatility\": \"implvolput\"})\n", "    atm_calls = atm_calls.groupby(['secid', 'date'])[[\"impl_volatility\"]].mean()\n", "    atm_calls = atm_calls.rename(columns={\"impl_volatility\": \"implvolcall\"})\n", "    atm_civpiv = pd.concat([atm_calls, atm_puts], axis=1)\n", "    atm_civpiv = atm_civpiv[\"implvolcall\"] - atm_civpiv[\"implvolput\"]\n", "    return atm_civpiv\n", "# atm_civpivtest= atm_civ_piv(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "atm_dcivpiv"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def atm_dcivpiv(opt_data):\n", "    sp500_op_ret = opt_data\n", "    atm_options = sp500_op_ret[(sp500_op_ret[\"moneyness\"] >= 0.9) & (sp500_op_ret[\"moneyness\"] <= 1.1)]\n", "    atm_puts_dpiv = atm_options.drop(atm_options[atm_options.cp_flag == 'C'].index)\n", "    dpiv = atm_puts_dpiv.groupby(['secid', 'date'])[[\"impl_volatility\"]].mean()\n", "    dpiv['diffp'] = dpiv['impl_volatility'].diff()\n", "    dpiv = dpiv['diffp']\n", "    atm_options = sp500_op_ret[(sp500_op_ret[\"moneyness\"] >= 0.9) & (sp500_op_ret[\"moneyness\"] <= 1.1)]\n", "    atm_calls_cpiv = atm_options.drop(atm_options[atm_options.cp_flag == 'P'].index)\n", "    cpiv = atm_calls_cpiv.groupby(['secid', 'date'])[[\"impl_volatility\"]].mean()\n", "    cpiv['diffc'] = cpiv['impl_volatility'].diff()\n", "    cpiv = cpiv['diffc']\n", "    dcivpiv_temp = pd.concat([cpiv, dpiv], axis=1)\n", "    atmdcivpiv = dcivpiv_temp[\"diffc\"] - dcivpiv_temp[\"diffp\"]\n", "    return atmdcivpiv\n", "# atm_dcivpiv=atm_dcivpiv_func(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "dpiv"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def dpiv(opt_data):\n", "    sp500_op_ret = opt_data\n", "    atm_options = sp500_op_ret[(sp500_op_ret[\"moneyness\"] >= 0.9) & (sp500_op_ret[\"moneyness\"] <= 1.1)]\n", "    atm_puts_dpiv = atm_options.drop(atm_options[atm_options.cp_flag == 'C'].index)\n", "    dpiv = atm_puts_dpiv.groupby(['secid', 'date'])[[\"impl_volatility\"]].mean()\n", "    dpiv['diffp'] = dpiv['impl_volatility'].diff()\n", "    dpiv = dpiv['diffp']\n", "    return dpiv\n", "# dpivtest=d_piv(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "dciv"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def dciv(opt_data):\n", "    sp500_op_ret = opt_data\n", "    atm_options = sp500_op_ret[(sp500_op_ret[\"moneyness\"] >= 0.9) & (sp500_op_ret[\"moneyness\"] <= 1.1)]\n", "    atm_calls_cpiv = atm_options.drop(atm_options[atm_options.cp_flag == 'P'].index)\n", "    cpiv = atm_calls_cpiv.groupby(['secid', 'date'])[[\"impl_volatility\"]].mean()\n", "    cpiv['diffc'] = cpiv['impl_volatility'].diff()\n", "    cpiv = cpiv['diffc']\n", "    return cpiv\n", "# dcivtest=d_civ(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "civpiv"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def ntm_civpiv(opt_data):\n", "    sp500_op_ret = opt_data\n", "    ntm_options = sp500_op_ret[(sp500_op_ret[\"moneyness\"] >= 0.8) & (sp500_op_ret[\"moneyness\"] <= 1.2)]\n", "    ntm_puts = ntm_options.drop(ntm_options[ntm_options.cp_flag == 'C'].index)\n", "    ntm_calls = ntm_options.drop(ntm_options[ntm_options.cp_flag == 'P'].index)\n", "    ntm_puts = ntm_puts.groupby(['secid', 'date'])[[\"impl_volatility\"]].mean()\n", "    ntm_puts = ntm_puts.rename(columns={\"impl_volatility\": \"implvolput\"})\n", "    ntm_calls = ntm_calls.groupby(['secid', 'date'])[[\"impl_volatility\"]].mean()\n", "    ntm_calls = ntm_calls.rename(columns={\"impl_volatility\": \"implvolcall\"})\n", "    ntm_civpiv = pd.concat([ntm_calls, ntm_puts], axis=1)\n", "    ntm_civpiv = ntm_civpiv[\"implvolcall\"] - ntm_civpiv[\"implvolput\"]\n", "    return ntm_civpiv\n", "# civpivtest=ntm_civpiv(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def ivd(opt_data):\n", "    sp500_op_ret = opt_data\n", "    impl_vol_sq = sp500_op_ret[\"impl_volatility\"]**2\n", "    sp500_op_ret[\"impl_vol_sq\"] = impl_vol_sq\n", "    sp500_op_ret.sort_values([\"optionid\", \"days_to_exp\"])\n", "    temp_ivd = sp500_op_ret.groupby(['secid', 'date', 'days_to_exp'])[[\"impl_vol_sq\"]].mean()\n", "    temp_ivd = temp_ivd.reset_index(level=['days_to_exp', 'secid', 'date'])\n", "    temp_ivd_diff = temp_ivd.groupby(['secid', 'date'])[\"impl_vol_sq\"].diff()\n", "    temp_ivd['impl_vol_sq_diff'] = temp_ivd_diff\n", "    temp_ivd['impl_difft'] = temp_ivd['impl_vol_sq_diff'] * temp_ivd['days_to_exp']\n", "    a = temp_ivd.groupby(['secid', 'date'])['impl_difft'].sum()\n", "    b = temp_ivd.groupby(['secid', 'date'])['impl_vol_sq_diff'].sum()\n", "    ivd = a / b\n", "    return ivd\n", "# ivdtest=iv_duration(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "iv_slope"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def ivslope(opt_data):\n", "    sp500_op_ret = opt_data\n", "    atm_options = sp500_op_ret[(sp500_op_ret[\"moneyness\"] >= 0.9) & (sp500_op_ret[\"moneyness\"] <= 1.1)]\n", "    short_term_options = atm_options[(sp500_op_ret[\"days_to_exp\"] <= 90)]\n", "    longterm_options = atm_options[(sp500_op_ret[\"days_to_exp\"] > 90)]\n", "    iv_longterm = longterm_options.groupby(['secid', 'date'])[\"impl_volatility\"].mean()\n", "    iv_shortterm = short_term_options.groupby(['secid', 'date'])[\"impl_volatility\"].mean()\n", "    iv_longterm.rename(\"ivlong\", inplace=True)\n", "    iv_shortterm.rename(\"ivshort\", inplace=True)\n", "    ivslope_temp = pd.concat([iv_longterm, iv_shortterm], axis=1)\n", "    result = ivslope_temp[\"ivlong\"] - ivslope_temp[\"ivshort\"]\n", "    return result\n", "# ivslopetest=iv_slope(sp500_op_ret)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%<br><br>\n", "funcs_by_Natasha = [toi, pcratio, vol, nopt, dvol, ailliq, pilliq,<br><br>\n", "                    pcpv, shrtfee, skewiv, atm_civpiv, atm_dcivpiv, <br><br>\n", "                    dpiv, dciv, ntm_civpiv, ivd, ivslope]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["funcs_by_Natasha = [toi, pcratio, vol, nopt, dvol, ailliq, pilliq,\n", "                    pcpv, shrtfee, skewiv,\n", "                    dpiv, dciv, ntm_civpiv, ivd, ivslope]  # deleted the two involving option returns"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results_Natasha = {}\n", "problems = []\n", "for func in funcs_by_Natasha:\n", "    try:\n", "        results_Natasha[func.__name__] = func(sp500_op_ret_w_permno)\n", "    except Exception as e:\n", "        print(f\"\"\"problem occured in {func.__name__}\\n\n", "              {e}\"\"\")\n", "        problems.append(func.__name__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for key in results_Natasha:\n", "    results_Natasha[key].rename(key, inplace=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["STOCKLEVELCHARS = results_Natasha"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "6. Stock vs. option volume (so)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stock_level_grouped = sp500_op_ret_w_permno.groupby(['secid', 'date'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_so(group):\n", "    agg_volu_option = group.volume.sum()\n", "    return group.share_volume.iloc[0] / agg_volu_option"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["so = stock_level_grouped.apply(get_so).rename('so', inplace=True)\n", "STOCKLEVELCHARS['so'] = so"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "7. log of so"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_lso(so):\n", "    return np.log(so)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lso = get_lso(so).rename('lso', inplace=True)\n", "STOCKLEVELCHARS['lso'] = lso"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "8. dso"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stock_level_grouped = sp500_op_ret_w_permno.groupby(['secid', 'date'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_dso(group):\n", "    agg_volu_option = (group.volume * group.mid_price).sum()\n", "    return group.share_volume.iloc[0] / agg_volu_option"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dso = stock_level_grouped.apply(get_dso).rename('dso', inplace=True)\n", "STOCKLEVELCHARS['dso'] = dso"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "9. ldso"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_ldso(dso):\n", "    return np.log(dso)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ldso = get_ldso(dso).rename('ldso', inplace=True)\n", "STOCKLEVELCHARS['ldso'] = ldso"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "13. Proportional bid-ask spread (pba)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stock_level_grouped = sp500_op_ret_w_permno.groupby(['secid', 'date'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_pba(group):\n", "    return (group.volume * (group.best_offer - group.best_bid) / (0.5 * (group.best_offer - group.best_bid))).sum() / group.volume.sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pba = stock_level_grouped.apply(get_pba).rename('pba', inplace=True)\n", "STOCKLEVELCHARS['pba'] = pba"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "30. Weighted put-call spread (vs_level)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stock_level_grouped = sp500_op_ret_w_permno.groupby(['secid', 'date'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_vs_level(group):\n", "    group = group.sort_values('cp_flag', ascending=True)\n", "    s_grouped = group.groupby(['strike_price', 'exdate'])\n", "    candi_key = []\n", "    for key, s_group in s_grouped:  # record keys of such s_group that has length 2\n", "        if s_group.shape[0] == 2:\n", "            candi_key += [key]\n", "    if not candi_key:\n", "        # print(f\"{s_group.shape[0]} shape\")\n", "        return np.nan\n", "    else:\n", "        # print(1)\n", "        weights = np.array([s_grouped.get_group(key).open_interest.sum() for key in candi_key])\n", "        values = np.array([s_grouped.get_group(key).impl_volatility.iloc[0]\n", "                           - s_grouped.get_group(key).impl_volatility.iloc[1] \n", "                           for key in candi_key])\n", "        return sum(weights * values) / sum(weights)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vs_level = stock_level_grouped.apply(get_vs_level).rename('vs_level')\n", "STOCKLEVELCHARS['vs_level'] = vs_level"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "31. Change in Weighted put-call spread (vs_change)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def vs_change(vs_level):\n", "    grouped_by_secid = vs_level.sort_index(level=1).groupby(level=0)\n", "    return grouped_by_secid.apply(lambda x: x - x.shift(1))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vs_change = vs_change(vs_level).rename('vs_change')\n", "STOCKLEVELCHARS['vs_change'] = vs_change"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["STOCKLEVELCHARS_df = pd.DataFrame(STOCKLEVELCHARS)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "# Bucket level<br><br>\n", "<br><br>\n", "What we can do here is indeed limited, since daily option data is unhandlable for us"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["BUCKETLEVELCHARS = {}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def tag_moneyness(row):\n", "    if row.cp_flag == 'C':\n", "        return 'OTM' if row.moneyness > 1.1 else ('ITM' if row.moneyness < 0.9 else 'ATM')\n", "    else:\n", "        return 'ITM' if row.moneyness > 1.1 else ('OTM' if row.moneyness < 0.9 else 'ATM')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sp500_op_ret_w_permno['moneyness'] = sp500_op_ret_w_permno.strike_price / sp500_op_ret_w_permno.adj_spot\n", "sp500_op_ret_w_permno['moneyness_class'] = sp500_op_ret_w_permno.apply(tag_moneyness, axis=1)\n", "sp500_op_ret_w_permno['maturity_class'] = sp500_op_ret_w_permno['days_to_exp'].map(lambda n: 'L' if n > 90 else 'S')\n", "sp500_op_ret_w_permno['bucket_class'] = sp500_op_ret_w_permno['moneyness_class'] + ',' + sp500_op_ret_w_permno['maturity_class']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "14. Open Interest vs. stock volume (oistock)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bucket_level_grouped = sp500_op_ret_w_permno.groupby(['secid', 'date', 'bucket_class'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_oistock(group):\n", "    stock_volu = group['share_volume'].iloc[0]\n", "    return group.open_interest.sum() / stock_volu"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["oistock = bucket_level_grouped.apply(get_oistock).rename('iostock')\n", "BUCKETLEVELCHARS['oistock'] = oistock"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "15. Volume (bucket_vol)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bucket_vol = bucket_level_grouped['volume'].sum().rename('bucket_vol')\n", "BUCKETLEVELCHARS['bucket_vol'] = bucket_vol"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "16. Dollor volume  (bucket_dvol)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bucket_dvol = bucket_level_grouped['dollar_volume'].sum().rename('bucket_dvol')\n", "BUCKETLEVELCHARS['bucket_dvol'] = bucket_dvol"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "17. Relative Volume (bucket_vol_share)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stock_vol = STOCKLEVELCHARS['vol']\n", "bucket_vol_share = (bucket_vol / stock_vol).rename('bucket_vol_share')\n", "BUCKETLEVELCHARS['bucket_vol_share'] = bucket_vol_share"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "18. Turnover (turnover)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["turnover = (bucket_level_grouped['volume'].sum() / bucket_level_grouped['open_interest'].sum()).rename('turnover')\n", "BUCKETLEVELCHARS['turnover'] = turnover"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["BUCKETLEVELCHARS_df = pd.DataFrame(BUCKETLEVELCHARS)\n", "BUCKETLEVELCHARS_df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "# Contract Level<br><br>\n", "<br><br>\n", "By Natasha"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%<br><br>\n", "###############<br><br>\n", "PART3 CHARACTERISTICS"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "call_indicator, put indicator"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["call_indicator = np.where((sp500_op_ret_w_permno[\"cp_flag\"] == \"C\"), 1, 0)\n", "sp500_op_ret_w_permno[\"C\"] = call_indicator\n", "put_indicator = np.where((sp500_op_ret_w_permno[\"cp_flag\"] == \"P\"), 1, 0)\n", "sp500_op_ret_w_permno[\"P\"] = put_indicator"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "opt_spread"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optspread = 2 * (sp500_op_ret_w_permno[\"best_offer\"] - sp500_op_ret_w_permno[\"best_bid\"]) / (sp500_op_ret_w_permno[\"best_offer\"] + sp500_op_ret_w_permno[\"best_bid\"])\n", "sp500_op_ret_w_permno[\"optspread\"] = optspread"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "embedlev"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["embedlev = sp500_op_ret_w_permno[\"spotprice\"] / sp500_op_ret_w_permno[\"mid_price\"] * abs(sp500_op_ret_w_permno[\"delta\"])\n", "sp500_op_ret_w_permno[\"embedlev\"] = embedlev"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "volga calculation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["d1 = np.log(sp500_op_ret_w_permno[\"spotprice\"] / sp500_op_ret_w_permno[\"strike_price\"]) + (sp500_op_ret_w_permno[\"ir_rate\"] + 0.5 * sp500_op_ret_w_permno[\"impl_volatility\"]) * sp500_op_ret_w_permno[\"yrs_to_exp\"] / (sp500_op_ret_w_permno[\"impl_volatility\"] * np.sqrt(sp500_op_ret_w_permno[\"yrs_to_exp\"]))\n", "d2 = d1 - sp500_op_ret_w_permno[\"impl_volatility\"] * np.sqrt(sp500_op_ret_w_permno[\"yrs_to_exp\"])\n", "N = np.exp(-0.5 * d1**2) / 2 / np.pi\n", "volga = np.sqrt(sp500_op_ret_w_permno[\"yrs_to_exp\"]) * N * d1 * d2 / sp500_op_ret_w_permno[\"impl_volatility\"]\n", "sp500_op_ret_w_permno[\"volga\"] = volga"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sp500_op_ret_w_permno['expiration_month'] = np.where((sp500_op_ret_w_permno[\"days_to_exp\"] <= 21), 1, 0)\n", "sp500_op_ret_w_permno['ttm'] = sp500_op_ret_w_permno[\"yrs_to_exp\"]\n", "sp500_op_ret_w_permno['iv'] = sp500_op_ret_w_permno['impl_volatility']\n", "sp500_op_ret_w_permno['oi'] = sp500_op_ret_w_permno['open_interest']\n", "sp500_op_ret_w_permno['doi'] = sp500_op_ret_w_permno['oi'] * sp500_op_ret_w_permno['mid_price']\n", "sp500_op_ret_w_permno['mid'] = sp500_op_ret_w_permno['mid_price']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Level_3_chars = ['C', 'P', 'expiration_month', 'ttm', 'moneyness', 'iv', 'delta',\n", "                 'gamma', 'theta', 'vega', 'volga', 'embedlev', 'oi', 'doi',\n", "                 'mid', 'optspread']  # , 'prev_option_ret']\n", "intrinsics = ['secid', 'permno', 'date', 'exdate', 'optionid', 'bucket_class', 'option_ret']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["CONTRACTLEVELCHARS_df = sp500_op_ret_w_permno[intrinsics + Level_3_chars]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%% [markdown]<br><br>\n", "# Merging results"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df0 = pd.merge(CONTRACTLEVELCHARS_df, ind_dummies, on=['permno', 'date'],how='inner')\n", "df1 = pd.merge(df0, BUCKETLEVELCHARS_df.reset_index(), on=['secid', 'date', 'bucket_class'])\n", "result = pd.merge(df1, STOCKLEVELCHARS_df.reset_index(), on=['secid', 'date'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["result"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["result.to_csv(Path(DATAROOT, 'option_characteristics.csv'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["result['yyyymm'] = result.date.dt.strftime('%Y%m').astype(int)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["result['yyyymm'].iloc[1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["monthly_stock_wide.yyyymm.iloc[1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["all_chars_df = pd.merge(result, monthly_stock_wide, on=['permno', 'yyyymm'], how='inner')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["all_chars_df.to_csv(Path(DATAROOT, 'all_characteristics.csv'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["list(all_chars_df.columns)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%% [markdown]<br>\n", "%%<br><br>\n", "all_chars_df"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}